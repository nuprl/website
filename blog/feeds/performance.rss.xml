<?xml version="1.0" encoding="utf-8"?> 
<rss version="2.0">
 <channel>
  <title>PRL Blog: Posts tagged 'performance'</title>
  <description>PRL Blog: Posts tagged 'performance'</description>
  <link>http://prl.ccs.neu.edu/blog/tags/performance.html</link>
  <lastBuildDate>Tue, 08 May 2018 15:37:37 UT</lastBuildDate>
  <pubDate>Tue, 08 May 2018 15:37:37 UT</pubDate>
  <ttl>1800</ttl>
  <item>
   <title>Sampling Gradual Typing Performance</title>
   <link>http://prl.ccs.neu.edu/blog/2018/05/08/sampling-gradual-typing-performance/?utm_source=performance&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-prl-ccs-neu-edu:-blog-2018-05-08-sampling-gradual-typing-performance</guid>
   <pubDate>Tue, 08 May 2018 15:37:37 UT</pubDate>
   <author>PRL</author>
   <description>
&lt;p&gt;This post explains the sampling method introduced in the paper &lt;a href="http://www.ccs.neu.edu/home/types/publications/publications.html#gm-pepm-2018"&gt;&lt;em&gt;On the Cost of Type-Tag Soundness&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- more--&gt;

&lt;h2 id="quick-reference-how-to-apply-the-method"&gt;Quick Reference: How to apply the method&lt;/h2&gt;

&lt;ol&gt;
 &lt;li&gt;Find an untyped program, measure its running time.&lt;/li&gt;
 &lt;li&gt;Define a &lt;em&gt;granularity&lt;/em&gt; for type annotations (by-function, by-module, by-program, &amp;hellip;.).&lt;/li&gt;
 &lt;li&gt;Define a sample size &lt;strong&gt;s&lt;/strong&gt; and number of samples &lt;strong&gt;r&lt;/strong&gt;.&lt;/li&gt;
 &lt;li&gt;Randomly select &lt;strong&gt;s&lt;/strong&gt; &lt;em&gt;configurations&lt;/em&gt; uniformly at random, measure their running time.&lt;/li&gt;
 &lt;li&gt;Repeat the previous step &lt;strong&gt;r&lt;/strong&gt; times.&lt;/li&gt;
 &lt;li&gt;Pick a positive real number &lt;strong&gt;D&lt;/strong&gt;.&lt;/li&gt;
 &lt;li&gt;Count the proportion of configurations in each sample with running time less-than-or-equal-to &lt;strong&gt;D&lt;/strong&gt;&lt;/li&gt;
 &lt;li&gt;Build a 95% confidence interval for the &lt;strong&gt;r&lt;/strong&gt; proportions computed in the previous step&lt;/li&gt;
 &lt;li&gt;Conclusion: there is a good chance that your interval contains the true proportion of configurations with running time less-than-or-equal-to &lt;strong&gt;D&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;h2 id="background-what-to-measure"&gt;Background: what to measure&lt;/h2&gt;

&lt;p&gt;A migratory typing system adds static typing to a dynamically-typed (or, untyped) language. The recipe for &amp;ldquo;adding static typing&amp;rdquo; has a few steps:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;add a syntax for type annotations&lt;/li&gt;
 &lt;li&gt;add a static type checker&lt;/li&gt;
 &lt;li&gt;add a semantics for statically-typed parts of the program&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;If the semantics for statically-typed parts of the program is &lt;strong&gt;not&lt;/strong&gt; the same  as the semantics for dynamically-typed parts, then it is important to measure  performance.&lt;/p&gt;

&lt;p&gt;The key question is: how does adding type annotations affect the  running time of a working program? We do not know how to answer this question directly.&lt;/p&gt;

&lt;p&gt;An easier question, that we can answer, is: for a few programs each with  one full set of type annotations, how does adding or removing the chosen type  annotations affect the running time of these programs?&lt;/p&gt;

&lt;p&gt;The next two sections give two methods for answering this question.&lt;/p&gt;

&lt;h2 id="exhaustive-method"&gt;Exhaustive Method&lt;/h2&gt;

&lt;p&gt;One way to answer our easier question is to remove type annotations one  &amp;ldquo;unit&amp;rdquo; at a time and measure the running time of all these partially-typed  programs. We call the &amp;ldquo;unit&amp;rdquo; the &lt;em&gt;granularity&lt;/em&gt; of the performance evaluation. For example, some choices for granularity are to remove types one module  at a time, to remove types one function at a time, or to remove types  one variable at a time. We call the &amp;ldquo;partially-typed programs&amp;rdquo; the &lt;em&gt;configurations&lt;/em&gt; of the original  dynamically-typed program. Note that the number of configurations depends on the choice of granularity  &amp;mdash; I can&amp;rsquo;t just use the word &lt;em&gt;configurations&lt;/em&gt; without telling you the  granularity I have in mind.&lt;/p&gt;

&lt;p&gt;After measuring the running time of all configurations, we can summarize the  results. One way to summarize is to pick a number &lt;strong&gt;D&lt;/strong&gt; and count the number of configurations  that run at most &lt;strong&gt;D&lt;/strong&gt; times slower than the original dynamically-typed program. If this number is large, then the takeaway is:  if &lt;em&gt;you&lt;/em&gt; are willing to accept at most a &lt;strong&gt;D&lt;/strong&gt;x slowdown, and you add your  own type annotations to your own program, then there&amp;rsquo;s some hope that your  configuration runs at most &lt;strong&gt;D&lt;/strong&gt; times slower than your original program.&lt;/p&gt;

&lt;blockquote&gt;
 &lt;p&gt;Credit for the exhaustive method: &lt;a href="https://www2.ccs.neu.edu/racket/pubs/popl16-tfgnvf.pdf"&gt;&lt;em&gt;Is Sound Gradual Typing Dead?&lt;/em&gt;&lt;/a&gt; and &lt;a href="https://www2.ccs.neu.edu/racket/pubs/ecoop2015-takikawa-et-al.pdf"&gt;&lt;em&gt;Toward Practical Gradual Typing&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id="simple-random-approximation-method"&gt;Simple Random Approximation Method&lt;/h2&gt;

&lt;p&gt;The method above does not scale to large programs or fine granularities  because it asks for an exponential number of measurements. E.g., if there are 20 units to add or remove types from, then there are 1 million  configurations to measure. Exponentials are bad.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://www.ccs.neu.edu/home/types/publications/publications.html#gm-pepm-2018"&gt;&lt;em&gt;On the Cost of Type-Tag Soundness&lt;/em&gt;&lt;/a&gt;,  suggests a method based on simple random sampling that answers a similar question. Instead of measuring the true proportion of configurations that run at most  &lt;strong&gt;D&lt;/strong&gt; times slower than the original dynamically-typed program, we:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;pick a sample size &lt;strong&gt;s&lt;/strong&gt; (in the paper, we used &lt;strong&gt;s = 10M&lt;/strong&gt; where &lt;strong&gt;M&lt;/strong&gt; is the number of units),&lt;/li&gt;
 &lt;li&gt;pick a number of samples &lt;strong&gt;r&lt;/strong&gt; (in the paper, we used &lt;strong&gt;r = 10&lt;/strong&gt;),&lt;/li&gt;
 &lt;li&gt;and build a 95% confidence interval for the true proportion of configurations  that run at most &lt;strong&gt;D&lt;/strong&gt; times slower than the original program (from the  &lt;strong&gt;r&lt;/strong&gt; proportions of configurations that run at most &lt;strong&gt;D&lt;/strong&gt; times slower than the  original program in each of the &lt;strong&gt;r&lt;/strong&gt; samples).&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;The method is outlined above, described in the paper, and validated in that paper&amp;rsquo;s appendix. Please let us know if you have more questions.&lt;/p&gt;

&lt;blockquote&gt;
 &lt;p&gt;Maybe you&amp;rsquo;re wondering, &amp;ldquo;gee why do they keep writing out &amp;lsquo;configurations that  run at most &amp;hellip;.&amp;rsquo; instead of something shorter?&amp;rdquo;. Well, the short version is &lt;em&gt;&lt;strong&gt;D&lt;/strong&gt;-deliverable&lt;/em&gt; and it was introduced in the &lt;a href="https://www2.ccs.neu.edu/racket/pubs/popl16-tfgnvf.pdf"&gt;&lt;em&gt;Is Sound Gradual Typing Dead?&lt;/em&gt;&lt;/a&gt; paper. Unfortunately, (1) that paper instantiated &lt;strong&gt;D&lt;/strong&gt; to &lt;strong&gt;3&lt;/strong&gt;-deliverable in order to  explain a few graphs and (2) at least two published papers (&lt;a href="https://dl.acm.org/citation.cfm?id=3009849"&gt;paper 1&lt;/a&gt;, &lt;a href="https://dl.acm.org/citation.cfm?id=3133878"&gt;paper 2&lt;/a&gt;)  now cite us as saying &lt;strong&gt;3&lt;/strong&gt;x overhead is the cutoff between a good migratory  typing system and a bad one.&lt;/p&gt;
 &lt;p&gt;&amp;hellip;&lt;/p&gt;
 &lt;p&gt;If we can&amp;rsquo;t trust scientists to understand, then we &lt;em&gt;definitely&lt;/em&gt; can&amp;rsquo;t trust  you folks on the internet.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id="faq"&gt;FAQ&lt;/h2&gt;

&lt;h3 id="q-what-is-the-sampling-method-useful-for"&gt;Q. What is the sampling method useful for?&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Making a confidence interval for the true proportion of configurations that  run at most &lt;strong&gt;D&lt;/strong&gt; times slower than some baseline, for your favorite value of &lt;strong&gt;D&lt;/strong&gt;.&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="q-what-is-the-sampling-method-not-useful-for"&gt;Q. What is the sampling method &lt;strong&gt;not&lt;/strong&gt; useful for?&lt;/h3&gt;

&lt;ul&gt;
 &lt;li&gt;Finding the slowest configuration.&lt;/li&gt;
 &lt;li&gt;Finding the average running time of all configurations.&lt;/li&gt;
 &lt;li&gt;Evaluations where &amp;ldquo;removing types&amp;rdquo; might involve changing &lt;strong&gt;List[Int]&lt;/strong&gt; to &lt;strong&gt;List[Dyn]&lt;/strong&gt;, etc.&lt;/li&gt;
 &lt;li&gt;Situations where its wrong to assume that a programmer will start from untyped and pick a configuration uniformly at random&lt;/li&gt;
 &lt;li&gt;&amp;hellip;. many more &amp;hellip;.&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="q-why-is-it-okay-to-choose-d-after-collecting-the-samples"&gt;Q. Why is it okay to choose &lt;strong&gt;D&lt;/strong&gt; after collecting the samples?&lt;/h3&gt;

&lt;p&gt;The &amp;ldquo;quick reference&amp;rdquo; at the top of this post suggests choosing a value for &lt;strong&gt;D&lt;/strong&gt;  (the cutoff between good and bad performance) after sampling configurations  and measuring their running time. This may sound strange, because (1) the value of &lt;strong&gt;D&lt;/strong&gt; affects our bottom-line  judgment about the proportion of configurations with good performance, and (2)  shouldn&amp;rsquo;t and value that affects the bottom line be fixed before taking samples? (To avoid accidental &lt;a href="https://en.wikipedia.org/wiki/Data_dredging"&gt;data dredging&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;The reason it is ok to pick &lt;strong&gt;D&lt;/strong&gt; after taking the sample is that the  running times in the sample are independent of the choice of &lt;strong&gt;D&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For example, if one person chose &lt;strong&gt;D=3&lt;/strong&gt; and a second person chose &lt;strong&gt;D=9&lt;/strong&gt;,  both would follow the same protocol independent of &lt;strong&gt;D&lt;/strong&gt; to take samples.&lt;/p&gt;

&lt;h3 id="q-how-does-migratory-typing-relate-to-gradual-typing"&gt;Q. How does migratory typing relate to gradual typing?&lt;/h3&gt;

&lt;p&gt;Gradual typing is not just about adding a type system to an existing programming  language. See &lt;a href="http://drops.dagstuhl.de/opus/volltexte/2015/5031/"&gt;&lt;em&gt;Refined Criteria for Gradual Typing&lt;/em&gt;&lt;/a&gt;  and &lt;a href="http://drops.dagstuhl.de/opus/volltexte/2017/7120/"&gt;&lt;em&gt;Migratory Typing: 10 Years Later&lt;/em&gt;&lt;/a&gt;  for details.&lt;/p&gt;

&lt;h3 id="q-do-you-have-code-i-can-use-to-plot-sampling-data"&gt;Q. Do you have code I can use to plot sampling data?&lt;/h3&gt;

&lt;p&gt;Yes, start here:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="http://docs.racket-lang.org/gtp-plot/index.html#%28def._%28%28lib._gtp-plot%2Fplot..rkt%29._samples-plot%29%29"&gt;http://docs.racket-lang.org/gtp-plot/index.html#%28def._%28%28lib._gtp-plot%2Fplot..rkt%29._samples-plot%29%29&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Please ask questions and open issues if you have trouble. The source is here:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://github.com/bennn/gtp-plot"&gt;https://github.com/bennn/gtp-plot&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;h3 id="q-where-is-code-for-the-sampling-paper"&gt;Q. Where is code for the sampling paper?&lt;/h3&gt;

&lt;p&gt;Start here:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://pkgd.racket-lang.org/pkgn/package/gm-pepm-2018"&gt;https://pkgd.racket-lang.org/pkgn/package/gm-pepm-2018&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Source is here:&lt;/p&gt;

&lt;ul&gt;
 &lt;li&gt;&lt;a href="https://github.com/nuprl/retic_performance"&gt;https://github.com/nuprl/retic_performance&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;h2 id="closing-thoughts"&gt;Closing Thoughts&lt;/h2&gt;

&lt;p&gt;Statistics is easy to do wrong. Please let us know if you think our method is doing bad statistics.&lt;/p&gt;</description></item>
  <item>
   <title>A few cores too many</title>
   <link>http://prl.ccs.neu.edu/blog/2016/08/03/a-few-cores-too-many/?utm_source=performance&amp;utm_medium=RSS</link>
   <guid isPermaLink="false">urn:http-prl-ccs-neu-edu:-blog-2016-08-03-a-few-cores-too-many</guid>
   <pubDate>Wed, 03 Aug 2016 14:09:02 UT</pubDate>
   <author>PRL</author>
   <description>
&lt;p&gt;Performance matters for software systems, but performance is not always easy  to measure. At the PRL we recently had a scare with some unreliable measurements. Here is the story.&lt;/p&gt;
&lt;!-- more--&gt;

&lt;p&gt;Last year, we proposed a method for evaluating the performance of gradual type  systems based on measuring &lt;em&gt;every possible configuration&lt;/em&gt; of typed and untyped  code that a programmer might explore &lt;a href="http://www.ccs.neu.edu/racket/pubs/popl16-tfgnvf.pdf"&gt;(pdf)&lt;/a&gt;. Given the freedom that gradual typing offers, this is the only realistic way to measure  the performance of a gradual type system.&lt;/p&gt;

&lt;p&gt;But it is a lot to measure! While developing the method, we spent over 3 months benchmarking a total of 75,844 configurations. Each configuration is a complete program and some gradual typings caused  some programs to slow by 50x or even 100x, so many of these configurations took  minutes to run.&lt;/p&gt;

&lt;p&gt;The next question we asked was naturally &amp;ldquo;how can we scale this method to large software projects?&amp;rdquo; In &lt;a href="http://docs.racket-lang.org/ts-reference/Libraries_Provided_With_Typed_Racket.html#%28part._.Porting_.Untyped_.Modules_to_.Typed_.Racket%29"&gt;our case&lt;/a&gt;,  the number of gradually typed configurations scaled exponentially with the number of modules. Current gradual type system for &lt;a href="https://github.com/mvitousek/reticulated"&gt;Python&lt;/a&gt;  and &lt;a href="http://www.di.ens.fr/~zappa/readings/ecoop15.pdf"&gt;JavaScript&lt;/a&gt;  are exponential in the number of &lt;em&gt;variables&lt;/em&gt; in the program.&lt;/p&gt;

&lt;p&gt;We explored two solutions:&lt;/p&gt;

&lt;ol&gt;
 &lt;li&gt;Max New began work on a prediction model (inspired by work  on &lt;a href="http://subs.emis.de/LNI/Proceedings/Proceedings213/185.pdf"&gt;software product lines&lt;/a&gt;)  to estimate the performance of &lt;code&gt;2^N&lt;/code&gt; configurations after polynomially-many measurements.&lt;/li&gt;
 &lt;li&gt;Asumu Takikawa and I shopped for a multi-core computer.&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;By Thanksgiving, we had bought a Linux machine with 2 &lt;a href="http://www.amd.com/en-us/products/server/opteron/6000/6300"&gt;AMD Opteron 6376 2.3GHz&lt;/a&gt;  processors (16 cores each) and put it to work running benchmarks on 29 cores simultaneously. Life was good.&lt;/p&gt;

&lt;p&gt;Later that winter, Max implemented a prediction algorithm. The basic idea was to focus on &lt;em&gt;boundaries&lt;/em&gt; between modules and isolate their  effect on performance. If two modules are untyped, their boundary will have zero cost. If the same two modules are typed, their boundary might result in an overall  performance improvement due to type-driven optimizations. And if one module is typed and the other untyped, their boundary will  suffer some cost of type checking at runtime. In general a program with &lt;code&gt;N&lt;/code&gt; modules has at most &lt;code&gt;N(N - 1) / 2&lt;/code&gt; internal boundaries,  so it is far more time-efficient to measure only the boundaries than to benchmark  &lt;code&gt;2^N&lt;/code&gt; gradually typed configurations.&lt;/p&gt;

&lt;p&gt;Fast-forward to March, we had a prototype prediction algorithm and it was time to test. Again using 29 cores (because, why not), we gathered cost/benefit numbers for  one 4-module benchmark and used them to predict performance for its 16 configurations. The results were not very good.&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="/img/a-few-cores-too-many-1.png" alt="Figure 1: True running time vs. predicted running time for 16 configurations" /&gt;
 &lt;p class="caption"&gt;Figure 1: True running time vs. predicted running time for 16 configurations&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;Those green circles are the ground truth, the average running time after 5 iterations of each config. The blue triangles are what we predicted. Except for configurations 0 and 8, the triangles are FAR off from the truth. Many are even negative &amp;hellip; obviously the algorithm needs work.&lt;/p&gt;

&lt;p&gt;But then, out of frustration, desperation, or just good luck, Max compared the  predictions to ground truth data gathered on a &lt;em&gt;single&lt;/em&gt; core, leaving the other 31  cores idle.&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="/img/a-few-cores-too-many-2.png" alt="Figure 2: Predictions made using measurements from a single core" /&gt;
 &lt;p class="caption"&gt;Figure 2: Predictions made using measurements from a single core&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;First off, the red &amp;ldquo;sequential truth&amp;rdquo; dots are slightly closer to the predicted triangles. Second &amp;mdash; and this is the scary part &amp;mdash; the red dots are very different from  the green dots. &lt;em&gt;Running on 1 core vs. 29 cores should not change the measurements!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;From here we tried increasing the running time of the benchmark,  removing I/O and system calls,  checking for hyperthreading (ARM cores don&amp;rsquo;t support it),  and even changing the cores&amp;rsquo; CPU governor. The hope was that results taken from 1 core could match results from &lt;code&gt;N&lt;/code&gt; cores,  for some &lt;code&gt;N &amp;gt; 1&lt;/code&gt;. It turns out &lt;code&gt;N = 2&lt;/code&gt; was stable, but even for &lt;code&gt;N = 3&lt;/code&gt; we found graphs like the following:&lt;/p&gt;

&lt;div class="figure"&gt;&lt;img src="/img/a-few-cores-too-many-3.png" alt="Figure 3: exact running times. Same-colored dots in each column should be tightly clustered." /&gt;
 &lt;p class="caption"&gt;Figure 3: exact running times. Same-colored dots in each column should be tightly clustered.&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;This data is for the same 16 configurations as the previous two graphs. Green dots are exact running times measured with 25 cores. Red dots are running times measured with 1 core. The red dots are much closer together, and always unimodal. The green dots are evidence that maybe the 32-core machine has, as Jan Vitek  put it, 30 cores too many.&lt;/p&gt;

&lt;blockquote&gt;
 &lt;p&gt;&amp;ldquo;Oh my. You think it&amp;rsquo;ll never happen to you. Well, now I&amp;rsquo;ve learned my lesson.&amp;rdquo;&lt;/p&gt;&lt;!-- bg: If anyone knows this quote I will be AMAZED. If anyone can even Google this quote, I'll buy them 2 beers and a pizza.--&gt;&lt;/blockquote&gt;

&lt;p&gt;And so, we said goodbye to the last 4 months of data and started over running at most two cores. The new results are all stable, but still we keep pinching ourselves.&lt;/p&gt;

&lt;p&gt;P.S. the results from &lt;a href="http://www.ccs.neu.edu/racket/pubs/#popl16-tfgnvf"&gt;POPL 2016&lt;/a&gt; are just fine,  as they were not taken on the new machine running more than 2 cores.  If you have time to confirm, that data is in our  &lt;a href="http://www.ccs.neu.edu/home/asumu/artifacts/popl-2016/"&gt;artifact&lt;/a&gt;  and in the &lt;a href="https://github.com/nuprl/gradual-typing-performance/tree/master/paper/popl-2016/data"&gt;gradual-typing-performance&lt;/a&gt; repo.&lt;/p&gt;</description></item></channel></rss>